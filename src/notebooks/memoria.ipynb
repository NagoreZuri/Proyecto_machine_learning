{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc4bb9e",
   "metadata": {},
   "source": [
    "## MEMORIA DEL PROYECTO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6349e",
   "metadata": {},
   "source": [
    "He comenzado a analizar y estudiar varios Datasets de la página de calificación de cine IMDB, he realizado una limpieza superficial para eliminar variables redundantes o con datos no usables para modelos predictivos. \n",
    "\n",
    "Enlace a los datasets brutos. [https://datasets.imdbws.com/]\n",
    "\n",
    "Con ellos he tabajado con un total de 3 datasets: \n",
    "\n",
    "         Title.ratings.tsv\n",
    "\n",
    "Donde estoy usando las columnas *averageRating* que veo la puntuación promedio de cada obra y *numVotes* para ver el número total de votos en IMDB\n",
    "\n",
    "\n",
    "\n",
    "        Title.basics.tsv\n",
    "\n",
    "Donde rescato las columnas *titleType*, *primaryTitle*, *starYear*, *runtimeMinute* y *genres* para ver el tipo de la obra, el título, el género y el año de estreno. También uso *PrimaryName* con el nombre del actor/actriz principal.\n",
    "\n",
    "\n",
    "\n",
    "        Title.principals.tsv\n",
    "        \n",
    "ID del IMDB del actor/actriz protagonista (puede ser redundante)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69157ae7",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e808c32",
   "metadata": {},
   "source": [
    "### LIMPIEZA Y ORGANIZACIÓN DE LOS DATOS    12/05/2025\n",
    "\n",
    "El último dataset con el que me quedo tiene un ttal de 323 mil filas y 10 columnas en un principio. Comienzo a ver sus características y y sus punto fuertes y débiles. \n",
    "\n",
    "1. Veo que en la columna **RunTime** tengo bastantes nulos, por tanto decido crear un nuevo dataset con sOlamente obras que superen los 60 minutos de duración, por lo que desaparecen esos nulos y el dataset se queda finalmentecon 140 mil filas. \n",
    "\n",
    "2. Creo una nueva columna numérica (TitleType_num) a partir de la columna TitleType numérica para poder tratarla más adelante \n",
    "\n",
    "3. Comienzo con los primeros gráficos y visualizo un mapa de Correlación, de momento, solamente con las columnas numéricas. \n",
    "\n",
    "![Correlacion_var_numéricas](graficos_eda/correlacion_variables_num.png)\n",
    "\n",
    "\n",
    "    Lo que más llama la atención: runtimeMinutes (-0.364): Correlación negativa moderada.\n",
    "Hallazgo interesante: A mayor duración, menor puntuación en promedio.\n",
    "\n",
    "4. Miro también el mapa de correlación pero con el dataset over 60 para ver las diferencias entre ellos en el resultado. \n",
    "\n",
    "![Correlacion_var_numéricas](graficos_eda/correlacion_var_over_60.png)\n",
    "\n",
    "    Aquí vemos cómo se pierde la correlación que existía entre la duración de la obra y su nota media, dando a entender que cuando eliminamos las obras de menos de 60 minutos de duración, la correlación pasa a ser positiva pero débil: 0.166\n",
    "Esto podría indicar que películas/series con duraciones adecuadas (ni muy cortas ni muy largas) son mejor valoradas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ce513",
   "metadata": {},
   "source": [
    "##### Pairplot\n",
    "\n",
    "Vamos a ver el pairplot con las columnas numéricas en un primer momento para ver el resultado y a relación entre variables.\n",
    "\n",
    "![Pairplot](graficos_eda/pairplot.png)\n",
    "\n",
    "1. averageRating vs. numVotes:  Hay una tendencia débil: ratings más altos suelen tener más votos, pero también hay muchos valores dispersos.\n",
    "    Esta relación no es lineal clara, pero sí podría ser útil como feature.\n",
    "\n",
    "2. averageRating vs. startYear o decade: Distribución muy dispersa.\n",
    "    Podría haber una ligera tendencia temporal, pero no parece determinante por sí sola.\n",
    "\n",
    "3. averageRating vs. runtimeMinutes:  Prácticamente no hay correlación clara.\n",
    "    Mucha dispersión, incluso con outliers extremos (películas de 4000 minutos).\n",
    "\n",
    "4. averageRating vs. titleType_num: Muestra estratificación discreta (ya que es una variable categórica transformada).\n",
    "    Podría ser útil si se codifica correctamente (OneHot o Embedding).\n",
    "\n",
    "\n",
    "#### Conclusión\n",
    "\n",
    "De momento, veo que solamente con las variables numéricas no me sirve para funcionar en un buen modelo predictivo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6de4a5",
   "metadata": {},
   "source": [
    "Vamos a ver ahora la distribución de ratings: \n",
    "\n",
    "![Distribución_ratings](graficos_eda/distribucion_rating.png)\n",
    "\n",
    "Donde podemos ver que la maroyía de las puntuaciones se quedan entre el 6,5 y el 8 con una cola poco relevante hacia el 0 y una bajada muy significativa en la puntuación máxima.\n",
    "\n",
    "En conclusión, las variables numéricas de mi dataset no son robustas y no hay una correlación clara, por tanto, no me vaticina un resultado óptimo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43399a",
   "metadata": {},
   "source": [
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a2278",
   "metadata": {},
   "source": [
    "**Decido entonces al no tener un dataset muy robusto, trabajar con las variables no numéricas que tiene.**\n",
    "\n",
    "\n",
    "1. PRIMERO, Reduzco la cantidad de filas en base a la columna **runMinute**. Elimino directamente las obras menores de 60 minutos ya que quiero centrarme en obras largas y decido así mismo eliminar todos los valores nulos que había en la columna. \n",
    "\n",
    "\n",
    "2. SEGUNDO. Elimino todos los nulos en las variables clave para que no interfieran en el análisis. Me quedo así con poco más de 240 mil filas. \n",
    "\n",
    "3. TERCERO. Conteo los géneros, creo una columna por cada uno de ellos con un definición binaria y aquellos géneros que aparecen menos de 100 veces, se colocan en una columna aparte llamada otros géneros para no saturar de información irrelevante. \n",
    "\n",
    "4. CUARTO. Creo una clumna categórica con el **AverageRating** en la que se clasifican como MALA < 4.5, REGULAR (4.6 - 6,5), BUENA (6,6 - 8,9), MUY BUENA (9 - 10)\n",
    "\n",
    "**MODIFICACIÓN**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92da4ea",
   "metadata": {},
   "source": [
    "### SIGO GRAFICÁNDO CON EL RESTO DE INFORMACIÓN \n",
    "\n",
    "\n",
    "![MEDIA_GENERO](graficos_eda/media_por_genero.png)\n",
    "\n",
    "El gráfico muestra qué géneros tienden a tener mejores valoraciones promedio\n",
    "\n",
    "        Géneros con barras más altas → tienen mejores ratings promedio.\n",
    "\n",
    "        Géneros con barras más bajas → tienden a tener valoraciones más bajas.\n",
    "\n",
    "\n",
    " ¿Para qué sirve esto?\n",
    "\n",
    "1. Ayuda a identificar patrones en el comportamiento del público.\n",
    "\n",
    "2. Tomar decisiones de negocio (por ejemplo, qué géneros producir o promocionar).\n",
    "\n",
    "3. Ingeniería de características (usar ls información para enriquecer modelos predictivos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4fc90c",
   "metadata": {},
   "source": [
    "![Distribución_catg](graficos_eda/distribucion_rating_categ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182a657",
   "metadata": {},
   "source": [
    "Vemos como en la categoría de MALA hay bastantes outliers muy bajos con una puntuación realmente baja mientras que el resto muestran bastantes menos. \n",
    "\n",
    "Por otro lado, también tenemos que la media esta bastante centrada en la mayoría exceptuando tal vez MUY BUENA que tiende a la baja ya que es muy raro conseguir una puntuación total de 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d69e2f",
   "metadata": {},
   "source": [
    "![Tipos_obras](graficos_eda/tipos_obras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cc38e",
   "metadata": {},
   "source": [
    "Para mostrar y confirmar que no es muy predictiva por lo sesgado de la información, graficamos la cantidad de tipos de obras que tenemos en el dataset para verlo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6570c",
   "metadata": {},
   "source": [
    "![Decada](graficos_eda/rating_x_decada.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f8e0e",
   "metadata": {},
   "source": [
    "Con la variable década ya que el promedio ronda entre los 5 y los 6.5 puntos en todas las décadas prácticamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7620d",
   "metadata": {},
   "source": [
    "![rating_titulo](graficos_eda/rating_x_titulo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8e73b",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26e0d1",
   "metadata": {},
   "source": [
    "#### TOCA AHORA HACER POR FIN EL TRAIN TEST SPLIT Y COMENZAR A TRABAJAR DE LLENO CON LOS MÉTODOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088b285",
   "metadata": {},
   "source": [
    "### Primera toma de contacto con el análisis predictivo: REGRESIÓN.\n",
    "\n",
    "Vamos a empezar a trabajar con el dataset una vez está procesado y limpiado. Comenzaré con un modelo sencillo de regresión para predecir **Average Rating**.\n",
    "\n",
    "| Modelo                        | Ventajas                                              | Consideraciones                                  |\n",
    "|------------------------------|--------------------------------------------------------|--------------------------------------------------|\n",
    "| Linear Regression / Ridge / Lasso | Rápidos, interpretables                             | Pueden quedarse cortos si hay no linealidad      |\n",
    "| Random Forest Regressor      | Captura no linealidades y es robusto                  | Puede sobreajustar si no se regula               |\n",
    "| Gradient Boosting (XGBoost / LightGBM) | Muy preciso, maneja missing y outliers         | Más lento de entrenar, requiere tuning           |\n",
    "| Neural Network (MLP)         | Ideal si tienes muchas variables, como géneros        | Requiere más datos y tuning                      |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Analizando modelos con Clasificación\n",
    "\n",
    "Predeciremos **rating_cat**. eniendo en cuenta que el averaceRating es un derivado directo. \n",
    "\n",
    "\n",
    "| Modelo                            | Ventajas                                                 | Consideraciones                              |\n",
    "|-----------------------------------|----------------------------------------------------------|----------------------------------------------|\n",
    "| Logistic Regression (multiclase)  | Baseline rápido e interpretable                          | Puede necesitar regularización y no capta relaciones no lineales              |\n",
    "| Random Forest Classifier          | Bueno para features tabulares y mezclas num/categ        | Puede ser pesado en memoria y lento                     |\n",
    "| XGBoost / LightGBM Classifier     | Alta precisión y eficiencia en das desvalanceados(mi caso)                            | Sensible a parámetros                        |\n",
    "| Ensemble Voting CLasifier (BalancedRandomForest + XGBoost) |Combina fortalezas de ambos modelos, mayor robustez                                 | Más costoso de entrenar                      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9859c",
   "metadata": {},
   "source": [
    "### ¿Qué planteo?\n",
    "\n",
    "Dependiendo el modelo que eliga, trabajaré con uno u otro target\n",
    "\n",
    "Clasificación:\n",
    "Si el objetivo es predecir rating_cat → modelo de clasificación  (Muy Buena, Buena, Regular, Mala)\n",
    "\n",
    "\n",
    "Regresión:\n",
    "Si el objetivo es predecir averageRating → modelo de regresión  (escala de 1 a 10 dependiendo la nota )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e065e0",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5405c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**MODIFICACIÓN**   EN BASE A LAS IRRELEVANCIA QUE HAY EN CADA FEATURE, EXISTE UNA NECESIDAD DE MODIFICARLAS PARA DESARROLLAR MEJOR EL DATASET.\n",
    "\n",
    "\n",
    "1. La columna **runMinute** recibe una modificación Y se incluyen todas las obras por encima de 15 minutos de duración para tener más rango de tipos de obras de trabajo \n",
    "\n",
    "2. elimino de la columna **Decade** creada para agrupar los años por décadas, de 1960 hacia abajo para eliminar aquellas décadas con números de votos muy pobres "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ede902",
   "metadata": {},
   "source": [
    "![rating_x_decada](graficos_eda/rating_x_decad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed4ea4",
   "metadata": {},
   "source": [
    "### partes del PAIRPLOT más significativas\n",
    "\n",
    "![pairplot1](graficos_eda/pairplot1.png)\n",
    "\n",
    "\n",
    "\n",
    "    Relación entre número de votos y la media de nota que recibe la obra audiovisual.Pùedo ver en qué punto se acumulan la mayor cantidad de votos. \n",
    "\n",
    "\n",
    "\n",
    "![pairplot2](graficos_eda/pairplot2.png)\n",
    "\n",
    "\n",
    "    Relaciones varias entre features. Relación bastante definida entre actor_mean_rating con el average rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f1d8f",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSOR. \n",
    "\n",
    "![Linear_reg](graficos_modelo/linear_regr.png)\n",
    "\n",
    "\n",
    "El modelo no trabaja bien con las features y se aleja mucho de una buena predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bfa70",
   "metadata": {},
   "source": [
    "### RANDOM FOREST\n",
    "\n",
    "![RF_reg](graficos_modelo/RF_regres.png)\n",
    "\n",
    "\n",
    "Este modelo mejora significativamente las métricas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85924c81",
   "metadata": {},
   "source": [
    "#### XGBOOST/LIGHTGBM\n",
    "\n",
    "El **Gradient Boosting** trabaja iterativamente ajustando un nuevo modelo para corregir los errores (residuos) del modelo anterior. Así, cada árbol se ajusta a los residuos de los árboles anteriores, y el modelo global mejora progresivamente.\n",
    "\n",
    "En el momento de usarlos, me he dado cuenta de que XGBoost y LightGBM han mostrado un desempeño razonablemente bueno, con LightGBM ligeramente superior en términos de R².\n",
    "\n",
    "Pero aun queda mucho margen de mejora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb54a1",
   "metadata": {},
   "source": [
    "### PRUEBAS DE MODELOS DE REGRESIÓN \n",
    "\n",
    "| Modelo                             | MSE     | MAE     | RMSE    | R² Score | Observaciones                       |\n",
    "|-----------------------------------|---------|---------|---------|----------|-------------------------------------|\n",
    "| Linear Regression / Ridge / Lasso |   1.22      |     0.82    |    1.10     |    0.37     |    El modelo comete errores grandes, equivocandose casi 0.83 puntos de 1  y Solo el 37% de la varianza en los ratings está explicada por el modelo. Esto indica un ajuste pobre                              |\n",
    "| Random Forest Regressor           | 0.66        |   0.56      |    0.81     |   0.65     |   El modelo se equivoca por 0.57 puntos en la predicción, con una capacidad de generalizar bastante razonable.                                 |\n",
    "| Gradient Boosting XGBoost  |   0.69  |   0.60      |     0.83    |     0.64     |  El modelo penaliza más los errores grandes, el R Score ligeramente peor. Cn parámetos ajustados puede ser mejor                              || Gradient Boosting XGBoost  |   0.69  |   0.60      |     0.83    |     0.64     |  El modelo penaliza más los errores grandes, el R Score ligeramente peor. Cn parámetos ajustados puede ser mejor                              |\n",
    "| Gradient Boosting XGBoost **(segundo intento)**  |   0.65  |   0.58      |     0.81    |     0.66     |  Menor error promedio en el descenso de MAE y MSE, No es una mejora drástica, pero si consistente                          |\n",
    " Gradient Boosting LightGBM (MLP)              |  0.75       |    0.63     |     0.87    |     0.66     |   Este modelo no da mejores resultados que los anteriores por lo que no parece ser el adecuado para este caso                                  |\n",
    "| Redes Neuronales              | 0.69        |    0.60     |     0.83    |     0.64     | indica un modelo moderadamente bueno, aunque hay margen de mejora, ya que no capta toda la complejidad del dataset                                | \n",
    "| Redes Neuronales  **(segundo intento)**              | 0.71        |    0.62     |     ---    |     0.63    | Usando Bayesian Optimization los resultados no varían significativamente dado la poca complejidad del dataset                             |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### PRUEBA FINAL CON GRADIENT BOOSTING XGBOOST\n",
    "\n",
    "| Modelo                             | MSE     | MAE     | RMSE    | R² Score | Observaciones                       |\n",
    "|-----------------------------------|---------|---------|---------|----------|-------------------------------------|\n",
    "| Gradient Boosting XGBoost  **(INTENTO FINAL)**              |    0.63     |    0.56     |    0.79    |  0.67    |  Mejor desempeño general entre los modelos probados. Explica el 67% de la varianza de los datos, con un error absoluto promedio menor a 0.6. Muestra solidez sin sobreajuste evidente. Optimizado con hiperparámetros ajustados.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b04e9d",
   "metadata": {},
   "source": [
    "![comparacion__modelos](graficos_modelo/comparcion_regresion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7836e",
   "metadata": {},
   "source": [
    "Este gráfico compara visualmente el desempeño de distintos modelos de regresión mediante tres métricas clave: MSE, MAE y R². Se observa que el modelo Gradient Boosting (Final) obtiene los valores más bajos de error (MSE y MAE), lo que indica mayor precisión. Además, tiene el R² más alto (0.672), mostrando que explica mejor la varianza de los datos. Modelos como la regresión lineal muestran peores resultados, con errores más altos y menor capacidad predictiva. En conjunto, el gráfico evidencia que Gradient Boosting Final es el modelo más robusto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d10b53",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10ecb2",
   "metadata": {},
   "source": [
    "### CONTEXTO ANTES DE EMPEZAR CLASIFICACIÓN \n",
    "\n",
    "![CONTEO_rating](graficos_eda/count_rating.png)\n",
    "\n",
    "Como se puede observar, se muestra claramente una distribución desequilibrada  con la categoría \"buena\" siendo con diferencia la más frecuente (~155,000 registros).\n",
    "Esto representa un riesgo de sesgo para muchos modelos, que tienden a optimizar para la clase mayoritaria.  \n",
    "\n",
    "\n",
    "Dado el problema de desbalance de clases Estudié diferentes estrategias para mitigar:\n",
    "\n",
    "1. Modelos estándar como línea base Logistic Regression y Random Forest sirvieron para evaluar qué tan grave era el problema con modelos sin ajustes.\n",
    "Resultado: pobre rendimiento en clases minoritarias.\n",
    "\n",
    "2. Random Forest con hiperparámetros\n",
    "Busqué mejorar con optimización, pero no resolvió el fondo del problema (seguía el sesgo hacia clases frecuentes).\n",
    "\n",
    "3. XGBoost con y sin pesos\n",
    "XGBoost ofrece buen rendimiento por diseño, pero no soluciona el desbalance por sí solo. Mejoré algo el recall de clases minoritarias (\"mala\", \"muy buena\").\n",
    "\n",
    "4. Modelos balanceados (Balanced RF, LightGBM con pesos)\n",
    "Estas versiones modifican internamente la forma en que se entrenan los árboles para prestar más atención a clases menos representadas.\n",
    "\n",
    "Resultado: mejor cobertura (recall alto), pero con pérdida de precisión (más falsos positivos).\n",
    "\n",
    "5. Modelo final: VotingClassifier (XGBoost + Balanced RF) XGBoost aporta precisión y Balanced RF recall.\n",
    "\n",
    "Resultado: un equilibrio robusto, especialmente importante cuando hay interés en detectar correctamente las clases raras.  No es una solución mágica, pero estable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce9b26",
   "metadata": {},
   "source": [
    "### PRUEBAS DE MODELOS DE CLASIFICACIÓN\n",
    "\n",
    "\n",
    "| Modelo                             | Accuracy     | Precision     | Recall   | F1-Score | Observaciones                       |\n",
    "|-----------------------------------|---------|---------|---------|----------|-------------------------------------|\n",
    "| Logistic Regression (multiclase)  |         0.70                 | B.0.77   M.0.59  MB.0.50  R.0.56        |   B.0.87    M.0.27   MB.0.00   R.0.53      |  B.0.81  M.0.37  MB.0.00  R.0.54   | Primera toma de contacto. El modelo tiene buen rendimiento con la clase 'BUENA' (f1=0.81), pero falla completamente con 'MUY BUENA' y 'MALA' (recall 0.27). no está capturando bien las clases minoritarias.\n",
    "| Random Forest Classifier   |     0.76    |   B.0.86   M.0.57  MB.0.60  R.0.63   |  B.0.87    M.0.40   MB.0.30   R.0.68  |  B.0.86   M.0.47   MB.0.40   R.0.65  | Equilibrio moderado entre clases, pero aún hay margen de mejora, especialmente en clases minoritarias. Las clases Mala y Muy buena tienen baja recall, especialmente en \"muy buena\" (0.30), lo que indica que el modelo no está identificando bien estas clases.\n",
    "| Random Forest Classifier **Con hiperparámetros**   |     0.77   |   B.0.86   M.0.57  MB.0.60  R.0.63   |  B.0.87   M.0.40   MB.0.30   R.0.69  |  B.0.86  M.0.47   MB.0.40  R.0.66  | Casi no hay diferencia con o sin parametrización. Llegando al límiteóptimo del modelo.\n",
    "| XGBoost  Classifier| 0.77 | B.0.86   M.0.60  MB.0.66  R.0.63  |  B.0.87   M.0.41  MB.0.27  R.0.70 |  B.0.87   M.0.48  MB.0.38  R.0.66 |  XGBClassifier espera etiquetas numéricas- Uso **LabelEncoder** para trabajar. |\n",
    " XGBoost  Classifier **pesos ajustados x clase** |  0.74 | B.0.90   M.0.46  MB.0.33  R.0.60   | B.0.80   M.0.58  MB.0.54  R.0.69   |  B.0.85   M.0.51  MB.0.41  R.0.64  |    El accuracy y la precisión general bajan ligeramente al aplicar pesos,  ligera pérdida de precisión en 'BUENA', pero mejora notable en recall para clases 'MUY BUENA' y 'MALA' |\n",
    "/ LightGBM Classifier **pesos ajustados**     |        0.65                     |   B.0.91   M.0.43  MB.0.11  R.0.58                      |B.0.65   M.0.71  MB.0.77  R.0.64 |  B.0.76   M.0.53  MB.0.20  R.0.61   | lase 2 tiene recall 0.77 pero precision 0.11 indicando muchos falsos positivos ya El modelo está clasificando demasiadas instancias como clase 'MALA', lo que daña la precisión general.Los pesos hacen que LightGBM “se obsesione” con detectar clases raras.\n",
    "|BalancedRandomForestClassifier | 0.66  | B.0.91   M.0.43  MB.0.13  R.0.58 |B.0.67   M.0.71  MB.0.77  R.0.63 | B.0.77   M.0.53  MB.0.22  R.0.60   |En general, el modelo aprende a identificar las clases más difíciles, aunque sacrifica precisión (muchos falsos positivos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebe551",
   "metadata": {},
   "source": [
    "#### OPCIÓN FINAL DE PRUEBA: Ensemble: votingClassifier (XGBoost + Balanced RF)\n",
    "\n",
    "| Modelo                             |  Accuracy    | Precisión    | Recall   | f1-Score | Observaciones                       |\n",
    "|-----------------------------------|---------|---------|---------|----------|-------------------------------------|\n",
    "|**Híbrido** votingClassifier (XGBoost + Balanced RF) |     0.77   |   B.0.88   M.0.57  MB.0.57  R.0.63    |  B.0.85   M.0.47  MB.0.35  R.0.71   |   B.0.87   M.0.51  MB.0.43  R.0.67  | Mantiene la precisión de XGBoost, especialmente para las clases dominantes y Gana algo en recall para clases difíciles gracias al efecto del Balanced Random Forest.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e54c5",
   "metadata": {},
   "source": [
    "![F1-Score](graficos_modelo/f1-Score_clas.png)\n",
    "\n",
    "Mejor F1 para clases minoritarias (MALA y MUY BUENA) respecto a otros modelos, que las ignoraban casi completamente. El ensemble combina fuerzas: XGBoost aporta precisión, Balanced RF mejora recall en clases minoritarias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b10c8",
   "metadata": {},
   "source": [
    "![Matriz](graficos_modelo/MC_hibrido_clasif.png)\n",
    "\n",
    "Buen desempeño general, aunque demasiadas BUENAS están siendo etiquetadas como REGULARES, lo que puede desvirtuar la calidad del output.\n",
    "\n",
    "El mayor punto débil del modelo es que la mayoría de las MUY BUENAS están siendo etiquetadas como simplemente BUENAS. No sabe diferenciar suficientemente entre MUY BUENA y BUENA. Quizás haya solapamiento fuerte entre estas.El modelo confunde MUY BUENA con BUENA y REGULAR con BUENA o MALA que no dejan de ser clases cercanas o con características similares.\n",
    "\n",
    "Esto es común en problemas con clases muy similares o con solapamiento en las features.\n",
    "\n",
    "Pero igualemente, a pesar de confusiones internas, mantiene buena precisión y recall globales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fae9a0",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe156a",
   "metadata": {},
   "source": [
    "Un detalle interesante es empezar a **trabajar con pesos** para darle menor valor a las clases mayoritarias y cederle espacio a las minoritarias. Y elige según tu prioridad:\n",
    "\n",
    "+ Si Prefiero detectar bien todas las clases, aunque baje un poco el accuracy usando pesos en el modelo XGBoost veo esos resultados. \n",
    "\n",
    "- Si prefiero máxima exactitud global sin importa fallar en las clases pequeñas, prescindo de los pesos.\n",
    "\n",
    "F1 Macro: 0.60 en promedio, el modelo tiene un desempeño moderado en todas las clases ya que no ignora las minoritarias. \n",
    "\n",
    "F1 Weighted: 0.75 como la clase 0 es muy grande, su buen rendimiento arrastra hacia arriba el promedio, aunque el modelo falle más en las clases pequeñas.  Favoreciendo las clases grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b3b72",
   "metadata": {},
   "source": [
    "        A DESTACAR: no entreno ni con KNN ni con SVM ya que estos métdos no funcionan bien con alta demanda de datos y no trabajan bien con un desvalance importante de clases que es mi caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b471157",
   "metadata": {},
   "source": [
    "#### Grafícos de las métricas de los diferentes modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c2642",
   "metadata": {},
   "source": [
    "![Accuracy](graficos_modelo/accuracy_class.png)\n",
    "\n",
    "![Precision](graficos_modelo/precision_class.png)\n",
    "\n",
    "![Recall](graficos_modelo/recall_class.png)\n",
    "\n",
    "![F1Score](graficos_modelo/fiscore_class.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010e945",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decba06d",
   "metadata": {},
   "source": [
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4afd8",
   "metadata": {},
   "source": [
    "### CONCLUSIÓN \n",
    "\n",
    "Viendo el dataset que se me presenta, abordé la búsqueda de mi objetivo desde el traget original usando modelos de regressión, y creando una nueva columna categórica para abordarlo desde modelos de clasificación.\n",
    "\n",
    "El escenario que se me presentaba era muy desvalanceado pero me enfoqué en sacarle el mayor partido\n",
    "\n",
    "Durante la primera fase, se abordó el problema como una **regresión multivariable**, donde el objetivo era predecir directamente el valor numérico del rating: Se probaron modelos como Linear Regression, Random Forest Regressor, XGBoost Regressor y LightGBM.\n",
    "\n",
    "Aunque algunos modelos lograron buen desempeño en términos de RMSE y R², se observó:\n",
    "\n",
    "+ Alta variabilidad en el error según el segmento.\n",
    "\n",
    "+ Dificultad para predecir valores extremos con precisión (sobre todo ratings muy altos o muy bajos).\n",
    "\n",
    "Como no conseguí un gran resulado, cambié el enfoque del problema como uno de clasificación por categorías.\n",
    "\n",
    "**Modelos de Clasificación** (Categorías de rating)\n",
    "En la segunda fase, el rating se transforma en una variable categórica: \"muy buena\", \"buena\", \"regular\", \"mala\", permitiendo aplicar técnicas más interpretables y robustas frente al desequilibrio de clases.\n",
    "Usé  múltiples modelos: Logistic Regression, Random Forest, XGBoost, LightGBM, y modelos balanceados (Balanced RF, pesos por clase).\n",
    "\n",
    "El principal desafío fue el grave desbalance de clases:\n",
    "\n",
    "+ \"Buena\" dominaba el dataset.\n",
    "\n",
    "+ \"Muy buena\" y \"mala\" eran escasas, dificultando su identificación.\n",
    "\n",
    "\n",
    "¿Qué Estrategias apliqué para abordar el desbalance?\n",
    "\n",
    "1. Pesos ajustados por clase (XGBoost, LightGBM).\n",
    "\n",
    "2. Implementación de modelos balanceados como BalancedRandomForestClassifier.\n",
    "\n",
    "\n",
    "**Evaluación con métricas por clase:** precision, recall y F1-score.\n",
    "\n",
    "**Modelo final elegido:**\n",
    "***VotingClassifier (XGBoost + BalancedRandomForest)***\n",
    "\n",
    "Combinó lo mejor de ambos mundos:\n",
    "\n",
    "+ XGBoost → Alta precisión en clases frecuentes.\n",
    "\n",
    "- Balanced RF → Mayor sensibilidad (recall) en clases minoritarias.\n",
    "\n",
    "Logró un F1-score equilibrado entre todas las clases, sin sacrificar demasiado accuracy global.\n",
    "\n",
    "\n",
    "\n",
    "Enfoqué el trabajo como un caso que pudiera tocarme fácilmente en un caso real como la existencia de desvalance y falta de datos.  Por tanto, me orienté  a resolver problemas lo mejor posible. El modelo teóricamente correcto (regresión) no me sirvió y pasé a clasificación, respaldado por pruebas empíricas y métricas claras.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
